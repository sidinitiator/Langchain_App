{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPUFKVCp3Ki2",
        "outputId": "12c65075-b3c5-4389-9293-ce8abcc428fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain==0.0.142\n",
            "  Downloading langchain-0.0.142-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting openai==0.27.4\n",
            "  Downloading openai-0.27.4-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting beautifulsoup4==4.12.2\n",
            "  Downloading beautifulsoup4-4.12.2-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting chromadb==0.3.21\n",
            "  Downloading chromadb-0.3.21-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting GitPython==3.1.31\n",
            "  Downloading GitPython-3.1.31-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.142) (6.0.2)\n",
            "Collecting SQLAlchemy<2,>=1 (from langchain==0.0.142)\n",
            "  Downloading SQLAlchemy-1.4.54-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.142) (3.10.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.142) (4.0.3)\n",
            "Collecting dataclasses-json<0.6.0,>=0.5.7 (from langchain==0.0.142)\n",
            "  Downloading dataclasses_json-0.5.14-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting gptcache>=0.1.7 (from langchain==0.0.142)\n",
            "  Downloading gptcache-0.1.44-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.142) (2.10.1)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.142) (1.26.4)\n",
            "Collecting openapi-schema-pydantic<2.0,>=1.2 (from langchain==0.0.142)\n",
            "  Downloading openapi_schema_pydantic-1.2.4-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting pydantic<2,>=1 (from langchain==0.0.142)\n",
            "  Downloading pydantic-1.10.18-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (152 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.2/152.2 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.142) (2.32.3)\n",
            "Collecting tenacity<9.0.0,>=8.1.0 (from langchain==0.0.142)\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.27.4) (4.66.5)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4==4.12.2) (2.6)\n",
            "Requirement already satisfied: pandas>=1.3 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.3.21) (2.1.4)\n",
            "Collecting hnswlib>=0.7 (from chromadb==0.3.21)\n",
            "  Downloading hnswlib-0.8.0.tar.gz (36 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting clickhouse-connect>=0.5.7 (from chromadb==0.3.21)\n",
            "  Downloading clickhouse_connect-0.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.1 kB)\n",
            "Collecting sentence-transformers>=2.2.2 (from chromadb==0.3.21)\n",
            "  Downloading sentence_transformers-3.1.1-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: duckdb>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from chromadb==0.3.21) (1.1.0)\n",
            "Collecting fastapi>=0.85.1 (from chromadb==0.3.21)\n",
            "  Downloading fastapi-0.115.0-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb==0.3.21)\n",
            "  Downloading uvicorn-0.31.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting posthog>=2.4.0 (from chromadb==0.3.21)\n",
            "  Downloading posthog-3.6.6-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython==3.1.31)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.142) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.142) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.142) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.142) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.142) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.142) (1.11.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from clickhouse-connect>=0.5.7->chromadb==0.3.21) (2024.8.30)\n",
            "Requirement already satisfied: urllib3>=1.26 in /usr/local/lib/python3.10/dist-packages (from clickhouse-connect>=0.5.7->chromadb==0.3.21) (2.2.3)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from clickhouse-connect>=0.5.7->chromadb==0.3.21) (2024.2)\n",
            "Collecting zstandard (from clickhouse-connect>=0.5.7->chromadb==0.3.21)\n",
            "  Downloading zstandard-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Collecting lz4 (from clickhouse-connect>=0.5.7->chromadb==0.3.21)\n",
            "  Downloading lz4-4.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.7 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.142)\n",
            "  Downloading marshmallow-3.22.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.142)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting starlette<0.39.0,>=0.37.2 (from fastapi>=0.85.1->chromadb==0.3.21)\n",
            "  Downloading starlette-0.38.6-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.85.1->chromadb==0.3.21) (4.12.2)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython==3.1.31)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (from gptcache>=0.1.7->langchain==0.0.142) (5.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3->chromadb==0.3.21) (2.8.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3->chromadb==0.3.21) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb==0.3.21) (1.16.0)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb==0.3.21)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb==0.3.21)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.142) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.142) (3.10)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.2.2->chromadb==0.3.21) (4.44.2)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.2.2->chromadb==0.3.21) (2.4.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.2.2->chromadb==0.3.21) (1.5.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.2.2->chromadb==0.3.21) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.2.2->chromadb==0.3.21) (0.24.7)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.2.2->chromadb==0.3.21) (10.4.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<2,>=1->langchain==0.0.142) (3.1.1)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.18.3->uvicorn[standard]>=0.18.3->chromadb==0.3.21) (8.1.7)\n",
            "Collecting h11>=0.8 (from uvicorn>=0.18.3->uvicorn[standard]>=0.18.3->chromadb==0.3.21)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb==0.3.21)\n",
            "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb==0.3.21)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb==0.3.21)\n",
            "  Downloading uvloop-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb==0.3.21)\n",
            "  Downloading watchfiles-0.24.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb==0.3.21)\n",
            "  Downloading websockets-13.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->sentence-transformers>=2.2.2->chromadb==0.3.21) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->sentence-transformers>=2.2.2->chromadb==0.3.21) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->sentence-transformers>=2.2.2->chromadb==0.3.21) (24.1)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette<0.39.0,>=0.37.2->fastapi>=0.85.1->chromadb==0.3.21) (3.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.2.2->chromadb==0.3.21) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.2.2->chromadb==0.3.21) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.2.2->chromadb==0.3.21) (3.1.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.38.0->sentence-transformers>=2.2.2->chromadb==0.3.21) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.38.0->sentence-transformers>=2.2.2->chromadb==0.3.21) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.38.0->sentence-transformers>=2.2.2->chromadb==0.3.21) (0.19.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.142)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers>=2.2.2->chromadb==0.3.21) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers>=2.2.2->chromadb==0.3.21) (3.5.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.39.0,>=0.37.2->fastapi>=0.85.1->chromadb==0.3.21) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.39.0,>=0.37.2->fastapi>=0.85.1->chromadb==0.3.21) (1.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.2.2->chromadb==0.3.21) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers>=2.2.2->chromadb==0.3.21) (1.3.0)\n",
            "Downloading langchain-0.0.142-py3-none-any.whl (548 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m548.8/548.8 kB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-0.27.4-py3-none-any.whl (70 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.3/70.3 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading beautifulsoup4-4.12.2-py3-none-any.whl (142 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.0/143.0 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chromadb-0.3.21-py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.4/46.4 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading clickhouse_connect-0.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (977 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m977.5/977.5 kB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.5.14-py3-none-any.whl (26 kB)\n",
            "Downloading fastapi-0.115.0-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.6/94.6 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gptcache-0.1.44-py3-none-any.whl (131 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.6/131.6 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openapi_schema_pydantic-1.2.4-py3-none-any.whl (90 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading posthog-3.6.6-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.3/54.3 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic-1.10.18-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m105.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sentence_transformers-3.1.1-py3-none-any.whl (245 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.3/245.3 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading SQLAlchemy-1.4.54-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m71.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading uvicorn-0.31.0-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.22.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Downloading starlette-0.38.6-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading uvloop-0.20.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m94.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-0.24.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (425 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m425.7/425.7 kB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading websockets-13.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (164 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.1/164.1 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lz4-4.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m68.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading zstandard-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m109.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Building wheels for collected packages: hnswlib\n",
            "  Building wheel for hnswlib (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hnswlib: filename=hnswlib-0.8.0-cp310-cp310-linux_x86_64.whl size=2364554 sha256=842caa655064147a4a46cf281906727f8a4558f8701df5529e1411d22250c786\n",
            "  Stored in directory: /root/.cache/pip/wheels/af/a9/3e/3e5d59ee41664eb31a4e6de67d1846f86d16d93c45f277c4e7\n",
            "Successfully built hnswlib\n",
            "Installing collected packages: monotonic, zstandard, websockets, uvloop, tenacity, SQLAlchemy, smmap, python-dotenv, pydantic, mypy-extensions, marshmallow, lz4, httptools, hnswlib, h11, beautifulsoup4, backoff, watchfiles, uvicorn, typing-inspect, starlette, posthog, openapi-schema-pydantic, gptcache, gitdb, clickhouse-connect, GitPython, fastapi, dataclasses-json, openai, langchain, sentence-transformers, chromadb\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.0.0\n",
            "    Uninstalling tenacity-9.0.0:\n",
            "      Successfully uninstalled tenacity-9.0.0\n",
            "  Attempting uninstall: SQLAlchemy\n",
            "    Found existing installation: SQLAlchemy 2.0.35\n",
            "    Uninstalling SQLAlchemy-2.0.35:\n",
            "      Successfully uninstalled SQLAlchemy-2.0.35\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.9.2\n",
            "    Uninstalling pydantic-2.9.2:\n",
            "      Successfully uninstalled pydantic-2.9.2\n",
            "  Attempting uninstall: beautifulsoup4\n",
            "    Found existing installation: beautifulsoup4 4.12.3\n",
            "    Uninstalling beautifulsoup4-4.12.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.12.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 1.4.15 requires pydantic>=2.7.0, but you have pydantic 1.10.18 which is incompatible.\n",
            "ipython-sql 0.5.0 requires sqlalchemy>=2.0, but you have sqlalchemy 1.4.54 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed GitPython-3.1.31 SQLAlchemy-1.4.54 backoff-2.2.1 beautifulsoup4-4.12.2 chromadb-0.3.21 clickhouse-connect-0.8.1 dataclasses-json-0.5.14 fastapi-0.115.0 gitdb-4.0.11 gptcache-0.1.44 h11-0.14.0 hnswlib-0.8.0 httptools-0.6.1 langchain-0.0.142 lz4-4.3.3 marshmallow-3.22.0 monotonic-1.6 mypy-extensions-1.0.0 openai-0.27.4 openapi-schema-pydantic-1.2.4 posthog-3.6.6 pydantic-1.10.18 python-dotenv-1.0.1 sentence-transformers-3.1.1 smmap-5.0.1 starlette-0.38.6 tenacity-8.5.0 typing-inspect-0.9.0 uvicorn-0.31.0 uvloop-0.20.0 watchfiles-0.24.0 websockets-13.1 zstandard-0.23.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain==0.0.142 openai==0.27.4 beautifulsoup4==4.12.2 chromadb==0.3.21 GitPython==3.1.31"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "from langchain.document_loaders import (\n",
        "    GitLoader,\n",
        "    YoutubeLoader,\n",
        "    DataFrameLoader\n",
        ")\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.schema import Document\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.agents import initialize_agent, Tool"
      ],
      "metadata": {
        "id": "5vrTkHWV3gAx"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Knowledge base\n",
        "kb_loader = GitLoader(\n",
        "    clone_url=\"https://github.com/neo4j-documentation/knowledge-base\",\n",
        "    repo_path=\"./repos/kb/\",\n",
        "    branch=\"master\",\n",
        "    file_filter=lambda file_path: file_path.endswith(\".adoc\")\n",
        "    and \"articles\" in file_path,\n",
        ")\n",
        "kb_data = kb_loader.load()\n",
        "print(len(kb_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSr1MC6d3yKs",
        "outputId": "a0cde0c7-8e38-4439-8623-f88fcc0e59da"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "309\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define text chunk strategy\n",
        "splitter = CharacterTextSplitter(\n",
        "  chunk_size=2000,\n",
        "  chunk_overlap=50,\n",
        "  separator=\" \"\n",
        ")\n",
        "# GDS guides\n",
        "gds_loader = GitLoader(\n",
        "    clone_url=\"https://github.com/neo4j/graph-data-science\",\n",
        "    repo_path=\"./repos/gds/\",\n",
        "    branch=\"master\",\n",
        "    file_filter=lambda file_path: file_path.endswith(\".adoc\")\n",
        "    and \"pages\" in file_path,\n",
        ")\n",
        "gds_data = gds_loader.load()\n",
        "# Split documents into chunks\n",
        "gds_data_split = splitter.split_documents(gds_data)\n",
        "print(len(gds_data_split))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sa3psjmH32VV",
        "outputId": "e6b009ba-e3e1-49f6-c983-0ecae369642d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "864\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install youtube-transcript-api"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71cyiF7Q4NFT",
        "outputId": "1824eee5-4cea-487a-e01a-4349ba31591e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting youtube-transcript-api\n",
            "  Downloading youtube_transcript_api-0.6.2-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from youtube-transcript-api) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->youtube-transcript-api) (2024.8.30)\n",
            "Downloading youtube_transcript_api-0.6.2-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: youtube-transcript-api\n",
            "Successfully installed youtube-transcript-api-0.6.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Youtube\n",
        "yt_loader = YoutubeLoader(\"1sRgsEKlUr0\")\n",
        "yt_data = yt_loader.load()\n",
        "yt_data_split = splitter.split_documents(yt_data)\n",
        "print(len(yt_data_split))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xd70Pc4L32MX",
        "outputId": "f4c44e1c-4142-44c5-e503-8f28528bc4a2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Medium\n",
        "article_url = \"https://raw.githubusercontent.com/tomasonjo/blog-datasets/main/medium/neo4j_articles.csv\"\n",
        "medium = pd.read_csv(article_url, sep=\";\")\n",
        "medium[\"source\"] = medium[\"url\"]\n",
        "medium_loader = DataFrameLoader(\n",
        "    medium[[\"text\", \"source\"]],\n",
        "    page_content_column=\"text\")\n",
        "medium_data = medium_loader.load()\n",
        "medium_data_split = splitter.split_documents(medium_data)\n",
        "print(len(medium_data_split))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYjsEVIV4RKi",
        "outputId": "a4053646-2b7e-4479-a2fd-db5038a13db5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2244\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Stackoverflow\n",
        "so_data = []\n",
        "for i in range(1, 20):\n",
        "    # Define the Stack Overflow API endpoint and parameters\n",
        "    api_url = \"https://api.stackexchange.com/2.3/questions\"\n",
        "    params = {\n",
        "        \"order\": \"desc\",\n",
        "        \"sort\": \"creation\",\n",
        "        \"filter\": \"!-MBrU_IzpJ5H-AG6Bbzy.X-BYQe(2v-.J\",\n",
        "        \"tagged\": \"neo4j\",\n",
        "        \"site\": \"stackoverflow\",\n",
        "        \"pagesize\": 100,\n",
        "        \"page\": i,\n",
        "    }\n",
        "    # Send GET request to Stack Overflow API\n",
        "    response = requests.get(api_url, params=params)\n",
        "    data = response.json()\n",
        "    # Retrieve the resolved questions\n",
        "    resolved_questions = [\n",
        "        question\n",
        "        for question in data[\"items\"]\n",
        "        if question[\"is_answered\"] and question.get(\"accepted_answer_id\")\n",
        "    ]\n",
        "\n",
        "    # Print the resolved questions\n",
        "    for question in resolved_questions:\n",
        "        text = (\n",
        "            \"Title:\",\n",
        "            question[\"title\"] + \"\\n\" + \"Question:\",\n",
        "            BeautifulSoup(question[\"body\"]).get_text()\n",
        "            + \"\\n\"\n",
        "            + BeautifulSoup(\n",
        "                [x[\"body\"] for x in question[\"answers\"] if x[\"is_accepted\"]][0]\n",
        "            ).get_text(),\n",
        "        )\n",
        "        source = question[\"link\"]\n",
        "        so_data.append(Document(page_content=str(text), metadata={\"source\": source}))\n",
        "print(len(so_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LgEO2UOI4yGC",
        "outputId": "3b1366b6-2669-47fa-d2c5-b369606d78ce"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "806\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9k7RDP15se0",
        "outputId": "69dff07b-6701-4665-b86f-641d98db1792"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.9.11)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.8.30)\n",
            "Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.5/1.1 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define embedding model\n",
        "OPENAI_API_KEY = \"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\"\n",
        "embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
        "\n",
        "sales_data = medium_data_split + yt_data_split\n",
        "sales_store = Chroma.from_documents(\n",
        "    sales_data, embeddings, collection_name=\"sales\"\n",
        ")\n",
        "\n",
        "support_data = kb_data + gds_data_split + so_data\n",
        "support_store = Chroma.from_documents(\n",
        "    support_data, embeddings, collection_name=\"support\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yoZQOlU44063",
        "outputId": "356b42bf-9cca-45c7-e7a1-8760c6415f88"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:chromadb:Using embedded DuckDB without persistence: data will be transient\n",
            "WARNING:chromadb:Using embedded DuckDB without persistence: data will be transient\n",
            "WARNING:langchain.embeddings.openai:Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-embedding-ada-002 in organization org-joFddCuox8TaIN2bra753imo on tokens per min (TPM): Limit 1000000, Used 619732, Requested 583584. Please try again in 12.198s. Visit https://platform.openai.com/account/rate-limits to learn more..\n",
            "WARNING:langchain.embeddings.openai:Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-embedding-ada-002 in organization org-joFddCuox8TaIN2bra753imo on tokens per min (TPM): Limit 1000000, Used 535966, Requested 583584. Please try again in 7.173s. Visit https://platform.openai.com/account/rate-limits to learn more..\n",
            "WARNING:langchain.embeddings.openai:Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-embedding-ada-002 in organization org-joFddCuox8TaIN2bra753imo on tokens per min (TPM): Limit 1000000, Used 457608, Requested 583584. Please try again in 2.471s. Visit https://platform.openai.com/account/rate-limits to learn more..\n",
            "WARNING:langchain.embeddings.openai:Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-embedding-ada-002 in organization org-joFddCuox8TaIN2bra753imo on tokens per min (TPM): Limit 1000000, Used 772039, Requested 561252. Please try again in 19.997s. Visit https://platform.openai.com/account/rate-limits to learn more..\n",
            "WARNING:langchain.embeddings.openai:Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-embedding-ada-002 in organization org-joFddCuox8TaIN2bra753imo on tokens per min (TPM): Limit 1000000, Used 694425, Requested 561252. Please try again in 15.34s. Visit https://platform.openai.com/account/rate-limits to learn more..\n",
            "WARNING:langchain.embeddings.openai:Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-embedding-ada-002 in organization org-joFddCuox8TaIN2bra753imo on tokens per min (TPM): Limit 1000000, Used 614239, Requested 561252. Please try again in 10.529s. Visit https://platform.openai.com/account/rate-limits to learn more..\n",
            "WARNING:langchain.embeddings.openai:Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for text-embedding-ada-002 in organization org-joFddCuox8TaIN2bra753imo on tokens per min (TPM): Limit 1000000, Used 536772, Requested 561252. Please try again in 5.881s. Visit https://platform.openai.com/account/rate-limits to learn more..\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(\n",
        "    model_name=\"gpt-3.5-turbo\",\n",
        "    temperature=0,\n",
        "    openai_api_key=OPENAI_API_KEY,\n",
        "    max_tokens=512,\n",
        ")"
      ],
      "metadata": {
        "id": "HBxVcIsS6RdY"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sales_template = \"\"\"As a Neo4j marketing bot, your goal is to provide accurate and helpful information about Neo4j,\n",
        "a powerful graph database used for building various applications.\n",
        "You should answer user inquiries based on the context provided and avoid making up answers.\n",
        "If you don't know the answer, simply state that you don't know.\n",
        "Remember to provide relevant information about Neo4j's features, benefits,\n",
        "and use cases to assist the user in understanding its value for application development.\n",
        "\n",
        "{context}\n",
        "\n",
        "Question: {question}\"\"\"\n",
        "SALES_PROMPT = PromptTemplate(\n",
        "    template=sales_template, input_variables=[\"context\", \"question\"]\n",
        ")\n",
        "sales_qa = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=sales_store.as_retriever(),\n",
        "    chain_type_kwargs={\"prompt\": SALES_PROMPT},\n",
        ")"
      ],
      "metadata": {
        "id": "reLL7-l-6WtR"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sales_qa.run(\"What are the main benefits of using Neo4j?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LpqgviO6eBL",
        "outputId": "362e2c99-cdc3-4acd-98b2-29c2c9cd18cf"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Some of the main benefits of using Neo4j include:\n",
            "\n",
            "1. Speed and Performance: Neo4j is known for its fast performance, especially when it comes to querying complex relationships in data. This makes it ideal for applications that require real-time data analysis.\n",
            "\n",
            "2. Flexibility: Neo4j's graph data model allows for flexible and dynamic data structures, making it easy to adapt to changing data requirements without the need for complex schema changes.\n",
            "\n",
            "3. Intuitive Data Modeling: The graph data model used by Neo4j closely aligns with how we naturally think about and work with data, making it easier to model and query relationships between entities.\n",
            "\n",
            "4. Scalability: Neo4j can handle large amounts of data and complex relationships, making it suitable for applications that require scalability and high availability.\n",
            "\n",
            "5. Graph Algorithms: Neo4j provides a wide range of built-in graph algorithms that can be used to analyze and extract insights from connected data, making it a powerful tool for data analysis and visualization.\n",
            "\n",
            "Overall, Neo4j's features and benefits make it a valuable tool for building applications that require complex data relationships and real-time data analysis.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "support_template = \"\"\"\n",
        "As a Neo4j Customer Support bot, you are here to assist with any issues\n",
        "a user might be facing with their graph database implementation and Cypher statements.\n",
        "Please provide as much detail as possible about the problem, how to solve it, and steps a user should take to fix it.\n",
        "If the provided context doesn't provide enough information, you are allowed to use your knowledge and experience to offer you the best possible assistance.\n",
        "\n",
        "{context}\n",
        "\n",
        "Question: {question}\"\"\"\n",
        "\n",
        "SUPPORT_PROMPT = PromptTemplate(\n",
        "    template=support_template, input_variables=[\"context\", \"question\"]\n",
        ")\n",
        "\n",
        "support_qa = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=support_store.as_retriever(),\n",
        "    chain_type_kwargs={\"prompt\": SUPPORT_PROMPT},\n",
        ")"
      ],
      "metadata": {
        "id": "gV1PGqIq6mlh"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(support_qa.run(\"\"\"\n",
        "I am having my graph in a VM and i want to use GDS Plugins in my graph.\n",
        "I didn't see any proper documentation to install it in my server where it was working only on locally.\n",
        "Anyone clear me this to install the GDS Plugin in the VM ?\n",
        "\"\"\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnpCTHAw6qfy",
        "outputId": "a4b6393d-a8db-4907-c01d-48bef8ae5cc4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To install the GDS plugin in your VM where your Neo4j server is running, you can follow these steps:\n",
            "\n",
            "1. Download the compatible version of the Neo4j Graph Data Science Library from the Neo4j website.\n",
            "\n",
            "2. Decompress the downloaded file and locate the `neo4j-graph-data-science-[version].jar` file.\n",
            "\n",
            "3. Move the `neo4j-graph-data-science-[version].jar` file into the `plugins` directory of your Neo4j server. The location of this directory can vary depending on your setup, but it is usually found under the `plugins` directory within the Neo4j installation directory.\n",
            "\n",
            "4. Edit the `neo4j.conf` file located in the `conf` directory of your Neo4j installation. Add the following configuration entry to allow unrestricted access to GDS procedures:\n",
            "```\n",
            "dbms.security.procedures.unrestricted=gds.*\n",
            "```\n",
            "\n",
            "5. Check if the procedure allowlist is enabled in the `neo4j.conf` file. If it is, add the GDS library to the allowlist:\n",
            "```\n",
            "dbms.security.procedures.allowlist=gds.*\n",
            "```\n",
            "\n",
            "6. Restart your Neo4j server to apply the changes.\n",
            "\n",
            "By following these steps, you should be able to successfully install and configure the GDS plugin in your VM where your Neo4j server is running. If you encounter any issues during the installation process, feel free to ask for further assistance.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the zero-shot-react-description agent will use the \"description\" string to select tools\n",
        "tools = [\n",
        "    Tool(\n",
        "        name = \"sales\",\n",
        "        func=sales_qa.run,\n",
        "        description=\"\"\"useful for when a user is interested in various Neo4j information,\n",
        "                       use-cases, or applications. A user is not asking for any debugging, but is only\n",
        "                       interested in general advice for integrating and using Neo4j.\n",
        "                       Input should be a fully formed question.\"\"\"\n",
        "    ),\n",
        "    Tool(\n",
        "        name = \"support\",\n",
        "        func=support_qa.run,\n",
        "        description=\"\"\"useful for when when a user asks to optimize or debug a Cypher statement or needs\n",
        "                       specific instructions how to accomplish a specified task.\n",
        "                       Input should be a fully formed question.\"\"\"\n",
        "    ),\n",
        "]"
      ],
      "metadata": {
        "id": "Yfn8t6oB7HhD"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True)"
      ],
      "metadata": {
        "id": "HwqP8Yew7K12"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent.run(\"\"\"What are some GPT-4 applications with Neo4j?\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "Gz5bRpB87QAv",
        "outputId": "ecd888a8-8fd7-4411-c787-f9d526beecdc"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI should provide general advice on integrating GPT-4 with Neo4j.\n",
            "Action: sales\n",
            "Action Input: Provide information on how GPT-4 can be integrated with Neo4j for various applications.\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mAs of my last update, I do not have specific information on integrating GPT-4 with Neo4j for various applications. However, Neo4j's flexible and powerful graph database can be used in conjunction with various technologies and tools to enhance application development. \n",
            "\n",
            "Neo4j's graph data model is well-suited for representing complex relationships and can be integrated with machine learning models like GPT-4 to analyze and derive insights from connected data. By leveraging Neo4j's capabilities for storing and querying graph data, developers can create applications that benefit from the rich contextual information provided by graph structures.\n",
            "\n",
            "I recommend exploring Neo4j's documentation and resources for guidance on integrating external technologies like GPT-4 with Neo4j for your specific application needs. Additionally, reaching out to Neo4j's developer community or support team may provide further insights and assistance in this integration process.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
            "Final Answer: For specific information on integrating GPT-4 with Neo4j for various applications, it is recommended to explore Neo4j's documentation, resources, developer community, or support team for guidance and assistance.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"For specific information on integrating GPT-4 with Neo4j for various applications, it is recommended to explore Neo4j's documentation, resources, developer community, or support team for guidance and assistance.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit openai langchain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9NZj2wD9DZh",
        "outputId": "7baf3c67-0bb0-46cb-de9f-808b4d16ae25"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.38.0-py2.py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (0.27.4)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.0.142)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: numpy<3,>=1.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.26.4)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (24.1)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.1.4)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (10.4.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (14.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.8.1)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.12.2)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.1.31)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
            "Collecting watchdog<5,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-4.0.2-py3-none-manylinux2014_x86_64.whl.metadata (38 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.10.5)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.4.54)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.5.14)\n",
            "Requirement already satisfied: gptcache>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.44)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.10.1)\n",
            "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.2.4)\n",
            "Requirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.18)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.11.1)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.22.0)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2024.8.30)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<2,>=1->langchain) (3.1.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.5)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.20.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.3.0->streamlit) (1.16.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (1.0.0)\n",
            "Downloading streamlit-1.38.0-py2.py3-none-any.whl (8.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m82.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m118.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-4.0.2-py3-none-manylinux2014_x86_64.whl (82 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.9/82.9 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 streamlit-1.38.0 watchdog-4.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "from langchain.llms import OpenAI\n",
        "\n",
        "st.title('🦜🔗 Quickstart App')\n",
        "\n",
        "openai_api_key = st.sidebar.text_input('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')\n",
        "\n",
        "def generate_response(input_text):\n",
        "  llm = OpenAI(temperature=0.7, openai_api_key=openai_api_key)\n",
        "  st.info(llm(input_text))\n",
        "\n",
        "with st.form('my_form'):\n",
        "  text = st.text_area('Enter text:', 'What are the three key pieces of advice for learning how to code?')\n",
        "  submitted = st.form_submit_button('Submit')\n",
        "  if not openai_api_key.startswith('sk-'):\n",
        "    st.warning('Please enter your OpenAI API key!', icon='⚠')\n",
        "  if submitted and openai_api_key.startswith('sk-'):\n",
        "    generate_response(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNQIHgCF9GZ8",
        "outputId": "69d38d90-43f2-444f-9583-1fa4b7f82536"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-09-30 17:25:13.216 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-09-30 17:25:13.303 \n",
            "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
            "  command:\n",
            "\n",
            "    streamlit run /usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py [ARGUMENTS]\n",
            "2024-09-30 17:25:13.305 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-09-30 17:25:13.307 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-09-30 17:25:13.309 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-09-30 17:25:13.310 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-09-30 17:25:13.312 Session state does not function when running a script without `streamlit run`\n",
            "2024-09-30 17:25:13.313 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-09-30 17:25:13.314 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-09-30 17:25:13.316 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-09-30 17:25:13.317 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-09-30 17:25:13.318 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-09-30 17:25:13.319 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-09-30 17:25:13.320 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-09-30 17:25:13.321 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-09-30 17:25:13.322 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-09-30 17:25:13.323 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-09-30 17:25:13.324 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-09-30 17:25:13.325 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-09-30 17:25:13.326 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-09-30 17:25:13.519 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2024-09-30 17:25:13.521 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ]
    }
  ]
}